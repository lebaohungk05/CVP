# Emotion Recognition using Deep Learning

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.10+-orange.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.2+-green.svg)
![OpenCV](https://img.shields.io/badge/OpenCV-4.7+-red.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

**Äá»“ Ã¡n mÃ´n há»c: EEE703068-1-3-24(N03) - Thá»‹ giÃ¡c mÃ¡y tÃ­nh**  
**Giáº£ng viÃªn hÆ°á»›ng dáº«n:** Nguyá»…n VÄƒn Tá»›i  
**NhÃ³m thá»±c hiá»‡n:** LÃª Báº£o HÆ°ng (TrÆ°á»Ÿng nhÃ³m), Nguyá»…n VÄƒn ThÃ¡i, Nguyá»…n Quang Hiá»‡p

---

## ğŸ“‹ Má»¥c lá»¥c / Table of Contents
1. [Giá»›i thiá»‡u / Introduction](#giá»›i-thiá»‡u--introduction)
2. [BÃ i toÃ¡n / Problem Statement](#bÃ i-toÃ¡n--problem-statement)
3. [Dá»¯ liá»‡u / Dataset](#dá»¯-liá»‡u--dataset)
4. [PhÆ°Æ¡ng phÃ¡p / Methodology](#phÆ°Æ¡ng-phÃ¡p--methodology)
5. [Kiáº¿n trÃºc Model / Model Architecture](#kiáº¿n-trÃºc-model--model-architecture)
6. [Káº¿t quáº£ / Results](#káº¿t-quáº£--results)
7. [CÃ i Ä‘áº·t / Installation](#cÃ i-Ä‘áº·t--installation)
8. [HÆ°á»›ng dáº«n sá»­ dá»¥ng / Usage](#hÆ°á»›ng-dáº«n-sá»­-dá»¥ng--usage)
9. [Cáº¥u trÃºc dá»± Ã¡n / Project Structure](#cáº¥u-trÃºc-dá»±-Ã¡n--project-structure)
10. [ÄÃ¡nh giÃ¡ / Evaluation](#Ä‘Ã¡nh-giÃ¡--evaluation)
11. [Káº¿t luáº­n / Conclusions](#káº¿t-luáº­n--conclusions)
12. [License](#license)
13. [Acknowledgments](#acknowledgments)

---

## ğŸ“– Giá»›i thiá»‡u / Introduction
Dá»± Ã¡n nÃ y xÃ¢y dá»±ng há»‡ thá»‘ng nháº­n diá»‡n cáº£m xÃºc khuÃ´n máº·t sá»­ dá»¥ng deep learning (CNN) trÃªn táº­p dá»¯ liá»‡u FER2013. Há»‡ thá»‘ng tá»± Ä‘á»™ng huáº¥n luyá»‡n, Ä‘Ã¡nh giÃ¡, lÆ°u láº¡i toÃ n bá»™ sá»‘ liá»‡u, biá»ƒu Ä‘á»“ vÃ  phÃ¢n tÃ­ch chi tiáº¿t giÃºp báº¡n dá»… dÃ ng viáº¿t bÃ¡o cÃ¡o khoa há»c hoáº·c á»©ng dá»¥ng thá»±c táº¿.

This project implements a facial emotion recognition system using deep learning (CNN) on the FER2013 dataset. The system automates training, evaluation, and reporting for easy scientific analysis or practical deployment.

---

## ğŸ“ BÃ i toÃ¡n / Problem Statement
- **Input**: áº¢nh khuÃ´n máº·t grayscale 48Ã—48 pixels
- **Output**: NhÃ£n cáº£m xÃºc dá»± Ä‘oÃ¡n (1 trong 7 cáº£m xÃºc: angry, disgust, fear, happy, sad, surprise, neutral)
- **Má»¥c tiÃªu / Goal**: XÃ¢y dá»±ng há»‡ thá»‘ng phÃ¢n loáº¡i cáº£m xÃºc tá»± Ä‘á»™ng, tá»‘i Æ°u hÃ³a Ä‘á»™ chÃ­nh xÃ¡c vÃ  hiá»‡u quáº£ tÃ­nh toÃ¡n.

---

## ğŸ“Š Dá»¯ liá»‡u / Dataset
- **Nguá»“n / Source**: FER2013 (Facial Expression Recognition 2013)
- **Äá»‹nh dáº¡ng / Format**: áº¢nh grayscale 48Ã—48 pixels
- **Sá»‘ lá»›p / Classes**: 7 cáº£m xÃºc cÆ¡ báº£n
- **Cáº¥u trÃºc thÆ° má»¥c / Directory structure**:
  ```
  data/
    train/
      angry/ disgust/ fear/ happy/ sad/ surprise/ neutral/
    test/
      angry/ ...
  ```
- **Tiá»n xá»­ lÃ½ / Preprocessing**:
  - Äá»c áº£nh, chuyá»ƒn grayscale / Read image, convert to grayscale
  - Chuáº©n hÃ³a vá» [0,1] / Normalize to [0,1]
  - One-hot encoding nhÃ£n / One-hot encode labels

---

## ğŸ”¬ PhÆ°Æ¡ng phÃ¡p / Methodology
- **Kiáº¿n trÃºc sá»­ dá»¥ng / Architecture**: Convolutional Neural Network (CNN) custom
- **Ká»¹ thuáº­t / Techniques**: Regularization (Dropout, BatchNorm), EarlyStopping, ReduceLROnPlateau
- **Tá»‘i Æ°u hÃ³a / Optimization**: Adam optimizer, learning rate schedule
- **ÄÃ¡nh giÃ¡ / Evaluation**: Confusion matrix, classification report, training/validation curves

---

## ğŸ¤– Kiáº¿n trÃºc Model / Model Architecture
```
Input (48Ã—48Ã—1)
    â†“
Conv2D(32) â†’ BatchNorm â†’ MaxPool â†’ Dropout(0.25)
    â†“
Conv2D(64) â†’ BatchNorm â†’ MaxPool â†’ Dropout(0.25)
    â†“
Conv2D(128) â†’ BatchNorm â†’ MaxPool â†’ Dropout(0.25)
    â†“
Conv2D(256) â†’ BatchNorm â†’ MaxPool â†’ Dropout(0.25)
    â†“
Flatten â†’ Dense(128) â†’ BatchNorm â†’ Dropout(0.5)
    â†“
Dense(7, softmax)
```
- **Regularization**: Dropout, BatchNorm
- **Optimizer**: Adam (lr=0.0001)
- **Callbacks**: EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

---

## ğŸ“ˆ Káº¿t quáº£ / Results
- **Test Accuracy**: ~46% (FER2013, CNN custom)
- **Best Validation Accuracy**: ~46%
- **Confusion Matrix**: LÆ°u táº¡i `results/confusion_matrix.png`
- **Chi tiáº¿t tá»«ng lá»›p**: Xem `results/classification_report.json`, `results/detailed_metrics.json`

### Key Findings
- Model nháº­n diá»‡n tá»‘t cÃ¡c cáº£m xÃºc phá»• biáº¿n (Happy, Surprise, Neutral)
- CÃ¡c cáº£m xÃºc khÃ³ (Disgust, Fear, Sad) thÆ°á»ng bá»‹ nháº§m láº«n
- Dá»¯ liá»‡u máº¥t cÃ¢n báº±ng áº£nh hÆ°á»Ÿng lá»›n Ä‘áº¿n káº¿t quáº£

---

## ğŸš€ CÃ i Ä‘áº·t / Installation
### YÃªu cáº§u / Requirements
- Python 3.8+
- CUDA GPU (khuyáº¿n nghá»‹ / recommended)
- RAM >= 8GB

### HÆ°á»›ng dáº«n / Instructions
1. **Clone repo**
```bash
git clone https://github.com/lebaohungk05/CV-project.git
cd CV-project
```
2. **Táº¡o mÃ´i trÆ°á»ng áº£o / Create virtual environment**
```bash
python -m venv venv
# Linux/Mac:
source venv/bin/activate
# Windows:
venv\Scripts\activate
```
3. **CÃ i dependencies / Install dependencies**
```bash
pip install -r requirements.txt
```
4. **Chuáº©n bá»‹ dá»¯ liá»‡u / Prepare data**
- Äáº·t dá»¯ liá»‡u vÃ o thÆ° má»¥c `data/` theo cáº¥u trÃºc trÃªn / Place data in `data/` as above

---

## ğŸ’» HÆ°á»›ng dáº«n sá»­ dá»¥ng / Usage
### Huáº¥n luyá»‡n mÃ´ hÃ¬nh / Train model
```bash
python train.py
```
- Model sáº½ lÆ°u táº¡i `models/emotion_model.h5`
- Káº¿t quáº£, biá»ƒu Ä‘á»“, bÃ¡o cÃ¡o lÆ°u táº¡i `results/`

### Nháº­n diá»‡n cáº£m xÃºc trá»±c tiáº¿p báº±ng webcam / Real-time emotion detection via webcam
```bash
python detect.py
```
- Nháº¥n `q` Ä‘á»ƒ thoÃ¡t / Press `q` to quit
- Nháº¥n `r` Ä‘á»ƒ reset bá»™ Ä‘áº¿m cáº£m xÃºc / Press `r` to reset emotion counters

### PhÃ¢n tÃ­ch káº¿t quáº£ / Analyze results
- Xem cÃ¡c file trong `results/`:
  - `confusion_matrix.png`, `classification_report.json`, `training_plots.png`, ...

---

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n / Project Structure
```
FER2013-EmotionRecognition/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ emotion_model.h5
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ classification_report.json
â”‚   â”œâ”€â”€ training_plots.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ train.py
â”œâ”€â”€ detect.py
â”œâ”€â”€ model.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ analyze_results.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“Š ÄÃ¡nh giÃ¡ / Evaluation
- **Metrics**: Accuracy, Precision, Recall, F1-score, Confusion Matrix
- **Chiáº¿n lÆ°á»£c / Strategy**: Train/Val/Test split, EarlyStopping, Learning rate schedule
- **Visualization**: Training/validation curves, confusion matrix heatmap

---

## ğŸ“ Káº¿t luáº­n / Conclusions
- CNN custom Ä‘áº¡t káº¿t quáº£ tá»‘t trÃªn FER2013 (~46%)
- Dá»¯ liá»‡u máº¥t cÃ¢n báº±ng lÃ  thÃ¡ch thá»©c lá»›n
- CÃ³ thá»ƒ cáº£i thiá»‡n thÃªm báº±ng transfer learning, augmentation, hoáº·c tÄƒng dá»¯ liá»‡u cho cÃ¡c lá»›p khÃ³

---

## ğŸ“„ License
This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ™ Acknowledgments
- Thanks to Prof. Nguyá»…n VÄƒn Tá»›i for guidance
- FER2013 dataset creators
- Open-source community for libraries and tools

---

<div align="center">
  <i>For questions or contributions, please open an issue or submit a pull request.</i>
</div>

## âš ï¸ LÆ°u Ã½ khi quáº£n lÃ½ mÃ£ nguá»“n vá»›i Git / Note on Git source management
- **KHÃ”NG push file dá»¯ liá»‡u lá»›n, file nÃ©n (archive.zip, *.zip, *.rar, ...) lÃªn GitHub.**
- Náº¿u lá»¡ add nháº§m, hÃ£y xÃ³a khá»i repo báº±ng / If you accidentally add, remove from repo with:
  ```bash
  git rm -r --cached archive.zip
  git rm -r --cached '*.zip'
  git commit -m "Remove archive files from repo"
  git push
  ```
- Äáº£m báº£o file `.gitignore` Ä‘Ã£ cÃ³ cÃ¡c dÃ²ng loáº¡i bá» file nÃ©n, dá»¯ liá»‡u, cache.

# Emotion Detection Web Application

A web application for real-time emotion detection using computer vision and deep learning.

## Features

- Real-time emotion detection using webcam
- Upload images for emotion analysis
- Beautiful and responsive UI
- System information display
- Support for 7 emotions: angry, disgust, fear, happy, sad, surprise, neutral

## Setup

1. Create a virtual environment (recommended):
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Run the application:
```bash
python app.py
```

4. Open your browser and navigate to:
```
http://localhost:5000
```

## Usage

1. **Webcam Mode**:
   - Click the "Capture" button to take a photo
   - The application will analyze the emotion in real-time

2. **Upload Mode**:
   - Click "Upload Image" to select an image from your computer
   - The application will analyze the emotion in the uploaded image

3. **Results**:
   - The predicted emotion will be displayed
   - A bar chart shows the probability distribution across all emotions
   - System information is displayed at the bottom of the page

## Requirements

- Python 3.7+
- Webcam (for real-time detection)
- Modern web browser with JavaScript enabled

## Note

Make sure to load your trained model in `app.py` by uncommenting and updating the model loading line:
```python
model = tf.keras.models.load_model('path_to_your_model')
```

## Project Structure

```
emotion-detection/
â”œâ”€â”€ app.py              # Main Flask application
â”œâ”€â”€ utils.py            # Utility functions
â”œâ”€â”€ requirements.txt    # Project dependencies
â”œâ”€â”€ templates/          # HTML templates
â”‚   â””â”€â”€ index.html     # Main page template
â””â”€â”€ static/            # Static files (CSS, JS, images)
    â””â”€â”€ uploads/       # Uploaded images storage
```

## Contributing

Feel free to submit issues and enhancement requests!